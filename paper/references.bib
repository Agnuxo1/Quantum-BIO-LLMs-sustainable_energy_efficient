@article{preskill2018quantum,
  title={Quantum Computing in the {NISQ} era and beyond},
  author={Preskill, John},
  journal={Quantum},
  volume={2},
  pages={79},
  year={2018},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

@article{devlin2018bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{chowdhery2022palm,
  title={{PaLM}: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and others},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}